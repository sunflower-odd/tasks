# VARIANT 3. Duplicate Detection Tool for Product Catalogs

## Описание

Вариант 3 из экзаменационного задания по дисциплине **Алгоритмы и структуры данных**

---

Эта программа позволяет находить потенциальные дубликаты товаров в каталоге, сравнивая новые товары с уже существующими. 
Алгоритм использует **расстояние Левенштейна** для оценки схожести строк, а также базовую предобработку текста (нормализация, удаление лишних символов, обработка синонимов цветов и исключение служебных слов).
Программа работает полностью на стандартных библиотеках Python и не использует сторонние библиотеки для сравнения строк.  

---

## Логика работы

1. Считываются данные из файлов с каталогом товаров и новыми товарами.  
2. Очищаются данные: приводятся к нижнему регистру, убираются лишние символы, нормализуются единицы, заменяются синонимы и исключаются ненужные слова.  
3. Токенизируются данные, разделяя числовые и текстовые токены и сортируя их.  
4. Формируются поисковые строки для каждого товара, объединяя слова и числа в одну строку.  
5. Для каждого нового товара вычисляется расстояние Левенштейна до всех товаров каталога и определяется степень схожести.  
6. Если схожесть превышает порог, товар добавляется в список дубликатов.  
7. Итоговый словарь с результатами сохраняется в файл `duplicates.json`.

## Структура проекта

- **main.py** — основной скрипт с функциями для предобработки данных, токенизации, поиска похожих товаров и записи результатов.  
- **config.py** — конфигурационный файл с настройками:
  - `USE_PREPROCESSING` — включение/выключение предобработки.
  - `COLOR_MAP` — словарь синонимов цветов.
  - `WORDS_TO_EXCLUDE` — список служебных слов для исключения.
  - `SIMILARITY_THRESHOLD` — порог схожести для определения дубликата (0–1).  
  - `CATALOG_FILE_NAME` — путь к файлу с каталогом товаров.  
  - `NEW_ITEMS_FILE_NAME` — путь к файлу с новыми товарами, которые мы проверяем на дубликаты, сравнивая с существующим каталогом.

- **catalog.txt** — пример входного файла каталога товаров. Каждая строка — один товар, первый токен — ID, остальные — характеристики.  
- **new_items.txt** — пример входного файла с новыми товарами, аналогичный формату каталога.  
- **duplicates.json** — выходной файл с результатами поиска дубликатов (формат - JSON).

---

## Основные функции и их логика

### 1. `_levenshtein_distance(a, b)`

- **Принимает:** две строки (`a`, `b`).  
- **Выполняет:** вычисляет расстояние Левенштейна — минимальное количество операций (вставка, удаление, замена), чтобы превратить одну строку в другую.  
- **Возвращает:** целое число — расстояние между строками.  

### 2. `clean_data(file_name)`

- **Принимает:** путь к текстовому файлу с товарами.  
- **Выполняет:**
  - Если включена предобработка:
    - Перевод текста в нижний регистр.  
    - Удаление всех символов кроме букв, цифр и пробелов.  
    - Объединение нескольких пробелов в один.  
    - Нормализация единиц памяти (`ГБ` → `gb`).  
    - Разделение строки на токены (слова и числа).  
    - Замена синонимов цветов через `COLOR_MAP`.  
    - Исключение служебных слов (`WORDS_TO_EXCLUDE`).  
  - Если предобработка отключена — просто разделяет строку на токены.  
- **Возвращает:** словарь вида `{item_id: [список токенов]}`.

### 3. `tokenize(cleaned_dict)`

- **Принимает:** словарь после очистки (`cleaned_dict`).  
- **Выполняет:** разделяет токены на числовые и текстовые, сортирует их.  
- **Возвращает:** структурированный словарь:
```python
{
    "item_id": {
        "numbers": ["128", "64"],
        "words": ["black", "phone"]
    },
    ...
}
```

### 4. `build_search_string(entry)`
- **Принимает:** словарь одного товара (entry) с ключами numbers и words.
- **Выполняет:** объединяет все токены в одну строку для поиска.
- **Возвращает:** строку вида "black phone 128 64".

### 5. `find_similar(query, search_index, threshold)`

**Принимает:**
- `query` — строка нового товара.  
- `search_index` — словарь всех товаров каталога в виде строк для поиска.  
- `threshold` — порог схожести (от 0 до 1).  

**Делает:**
- Сравнивает `query` со всеми товарами каталога с помощью `_levenshtein_distance`.  
- Вычисляет степень схожести

- **Возвращает:** список найденных дубликатов и степень схожести

### 6. `main(new_items_file_name, catalog_file_name)` 
- реализует полную логику пайплайна

## **Использование программы**

1. **Подготовьте входные файлы:**
   - `catalog.txt` — каталог товаров. Каждая строка:
     ```
     catalog_id характеристика1 характеристика2 ...
     ```
     Пример:
     ```
     catalog_001 Red Phone 128GB 5G
     catalog_002 Blue Phone 64GB LTE
     ```
   - `new_items.txt` — новые товары для проверки, в том же формате:
     ```
     new_item_id характеристика1 характеристика2 ...
     ```
     Пример:
     ```
     new_item_001 Red Mobile 128 gb 5g
     new_item_002 Black Notebook 16gb 512 ssd
     ```

2. **Настройте конфигурацию в файле `config.py`:**
   - `USE_PREPROCESSING` — включение или отключение предобработки текста (рекомендуется установить `True`).  
   - `COLOR_MAP` — словарь синонимов цветов.  
   - `WORDS_TO_EXCLUDE` — список слов, не влияющих на идентификацию товара.  
   - `SIMILARITY_THRESHOLD` — порог схожести (от 0 до 1).  
   - `CATALOG_FILE_NAME` — путь к файлу каталога.  
   - `NEW_ITEMS_FILE_NAME` — путь к файлу с новыми товарами.

3. **Запустите скрипт:**
```bash
python main.py
```

4. Ожидаемый результат находится в файле **duplicates.json**:
``` SQL
{
    "new_item_001": [
        {"catalog_id": "catalog_001", "similarity_score": 0.95}
    ],
    "new_item_002": [
        {"catalog_id": "catalog_003", "similarity_score": 0.97}
    ],
    "new_item_003": [
        {"catalog_id": "catalog_004", "similarity_score": 0.93}
    ]
}
```